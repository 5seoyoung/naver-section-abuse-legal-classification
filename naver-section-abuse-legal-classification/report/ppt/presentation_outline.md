# 네이버 뉴스 섹션별 악플 법적 유형 분류 연구
## 발표 자료 개요

---

## 슬라이드 1: 표지
- **제목**: 네이버 뉴스 섹션별 악플 법적 유형의 분포 차이와 자동분류 모델 비교 연구
- **영문 제목**: Section-Specific Distribution and Automatic Classification of Legal-Type Abusive Comments in Naver News
- **연구자명**
- **날짜**

---

## 슬라이드 2: 연구 배경 및 목적
### 연구 배경
- 온라인 뉴스 댓글의 악플 문제
- 법적 책임 가능성 (명예훼손, 모욕, 혐오표현 등)

### 연구 목적
- **RQ1**: 섹션별 악플 법적 유형 분포 차이 분석
- **RQ2**: 머신러닝 기반 자동 분류 가능성 검증

---

## 슬라이드 3: 연구 방법론
### 데이터 수집
- 플랫폼: 네이버 뉴스
- 섹션: 정치, 사회, 연예
- 규모: 섹션별 500개, 총 1,500개

### 분류 기준 (6개 카테고리)
- A: 명예훼손형
- B: 모욕형
- C: 혐오표현형
- D: 협박·위협형
- E: 성희롱·성폭력형
- F: 악플 아님

---

## 슬라이드 4: 분류 모델
### 3가지 Baseline 모델
1. **Baseline 1**: TF-IDF + Logistic Regression
   - 빠른 학습, 해석 가능
2. **Baseline 2**: KoBERT 임베딩 + SVM
   - 사전학습된 한국어 임베딩 활용
3. **Baseline 3**: KoBERT Fine-tuning
   - 태스크 특화 미세조정

---

## 슬라이드 5: 섹션별 분포 분석 결과
### 주요 통계
- **전체 악플 비율**: 4.3% (64개/1,500개)
- **섹션별 악플 비율**:
  - 정치: 7.2% ⬆️
  - 사회: 4.2%
  - 연예: 1.4% ⬇️

### 카이제곱 검정
- χ² = 22.61, p < 0.001
- **결론**: 섹션별 분포 차이가 통계적으로 유의함

---

## 슬라이드 6: 분포 시각화
- 섹션별 라벨 분포 막대 그래프
- 히트맵 (섹션 × 라벨)
- (그래프 이미지 삽입)

---

## 슬라이드 7: 모델 성능 결과
### Baseline 1: TF-IDF + LR
| 지표 | Train | Val/Test |
|------|-------|----------|
| Accuracy | 99.78% | 96.33% |
| Macro F1 | 97.70% | 43.28% |
| Weighted F1 | 99.79% | 94.95% |

### 분석
- 높은 정확도 달성
- 클래스 불균형으로 인한 Macro F1 저하

---

## 슬라이드 8: Confusion Matrix
- Baseline 1의 Confusion Matrix 시각화
- (이미지 삽입)

---

## 슬라이드 9: 주요 발견사항
1. **정치 섹션의 악플 비율이 가장 높음**
   - 정치적 논쟁 환경의 영향
2. **클래스 불균형 문제**
   - F(악플 아님) 95.7% vs 악플 4.3%
3. **모델 성능**
   - 높은 정확도, 낮은 Macro F1

---

## 슬라이드 10: 한계점 및 향후 연구
### 한계점
- 클래스 불균형 문제
- 소규모 데이터셋 (1,500개)
- 자동 라벨링의 정확도 한계

### 향후 연구 방향
- 클래스 불균형 대응 기법 적용
- 더 큰 규모의 데이터셋 구축
- KoBERT Fine-tuning 모델 완전 평가
- 섹션별 특화 모델 개발

---

## 슬라이드 11: 결론
- 섹션별 악플 분포 차이 확인 (통계적으로 유의)
- 자동 분류 모델의 실용 가능성 검증
- 클래스 불균형 해결을 통한 성능 개선 필요

---

## 슬라이드 12: Q&A
- 감사합니다
- 질문 환영

---

## 시각화 자료 체크리스트
- [ ] 섹션별 라벨 분포 막대 그래프
- [ ] 히트맵 (섹션 × 라벨)
- [ ] Confusion Matrix (Train/Val/Test)
- [ ] 모델 성능 비교 그래프
- [ ] 카이제곱 검정 결과 표

