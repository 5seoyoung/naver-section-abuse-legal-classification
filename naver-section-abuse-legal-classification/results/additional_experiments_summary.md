# 추가 실험 결과 요약

## 실험 1: 섹션별 전용 모델 학습 비교

### 목적
섹션별 특화 모델이 전체 데이터로 학습한 모델보다 성능이 우수한지 검증

### 실험 설정
- 모델: Baseline 1 (TF-IDF + Logistic Regression)
- 섹션별로 독립적으로 학습
- Train/Val/Test = 6:2:2 (Stratified Split)

### 결과

#### 전체 데이터 모델 (baseline1)
- **Test Accuracy**: 96.33%
- **Test Macro F1**: 43.28%
- **Test Weighted F1**: 94.95%

#### 섹션별 전용 모델

| 섹션 | Test Accuracy | Test Macro F1 | Test Weighted F1 |
|------|--------------|---------------|------------------|
| **정치** | 94.00% | 34.22% | 91.69% |
| **사회** | 96.00% | 24.49% | 94.04% |
| **연예** | 99.00% | 49.75% | 98.50% |

### 주요 발견사항

1. **연예 섹션 전용 모델이 가장 우수한 성능**
   - Macro F1: 49.75% (전체 모델 43.28% 대비 +6.47%p)
   - Accuracy: 99.00% (전체 모델 96.33% 대비 +2.67%p)
   - **해석**: 연예 섹션의 단순한 악플 패턴(모욕형 85.71%)으로 인해 섹션 특화 모델이 효과적

2. **정치 섹션 전용 모델은 성능 저하**
   - Macro F1: 34.22% (전체 모델 대비 -9.06%p)
   - **해석**: 정치 섹션의 다양한 악플 유형으로 인해 데이터 부족 시 성능 저하

3. **사회 섹션 전용 모델은 유사한 성능**
   - Macro F1: 24.49% (전체 모델 대비 -18.79%p)
   - **해석**: 균형잡힌 악플 구조이지만 소규모 데이터로 인한 성능 저하

### 결론
- **연예 섹션**: 섹션별 전용 모델이 효과적 (Macro F1 +6.47%p 향상)
- **정치/사회 섹션**: 전체 데이터로 학습한 모델이 더 우수
- **시사점**: 섹션별 특성에 따라 모델 전략을 달리해야 함

---

## 실험 2: 클래스 불균형 대응 기법 (SMOTE)

### 목적
SMOTE 오버샘플링을 통해 소수 클래스(악플) 탐지 성능 개선

### 실험 설정
- 모델: Baseline 1 (TF-IDF + Logistic Regression)
- 기법: SMOTE (Synthetic Minority Oversampling Technique)
- 비교: 기본 모델 vs SMOTE 적용 모델

### 결과

| 모델 | Test Accuracy | Test Macro F1 | Test Weighted F1 |
|------|--------------|---------------|------------------|
| **baseline1** (기본) | 96.33% | **43.28%** | 94.95% |
| **baseline1_smote** | 96.00% | 36.99% | 94.21% |

### 주요 발견사항

1. **SMOTE 적용 시 Macro F1 성능 저하**
   - Macro F1: 43.28% → 36.99% (-6.29%p)
   - **해석**: 소규모 데이터셋(악플 64개)에서 SMOTE가 오히려 노이즈를 생성

2. **Accuracy는 유사한 수준 유지**
   - Accuracy: 96.33% → 96.00% (-0.33%p)
   - **해석**: 다수 클래스(F) 예측 성능은 유지

3. **Weighted F1도 소폭 하락**
   - Weighted F1: 94.95% → 94.21% (-0.74%p)

### 결론
- **SMOTE는 본 데이터셋에서 효과적이지 않음**
- 소규모 데이터셋(악플 64개)에서는 합성 샘플이 오히려 성능 저하
- **시사점**: 더 큰 규모의 데이터셋에서 SMOTE를 재검증하거나, 다른 불균형 대응 기법(언더샘플링, 클래스 가중치 조정 등) 시도 필요

---

## 실험 3: KoBERT 모델 재현성 확보 및 평가

### 목적
KoBERT 기반 모델의 저장/로드 문제 해결 및 성능 평가

### 개선 사항
- Baseline2: KoBERT 임베딩을 별도로 저장하여 pickle 의존성 제거
- Baseline3: 모델 state dict 저장 방식 개선

### 결과

#### Baseline2 (KoBERT 임베딩 + SVM)
- **Test Accuracy**: 95.00%
- **Test Macro F1**: 24.36%
- **Test Weighted F1**: 93.21%

### 주요 발견사항

1. **Baseline2는 Baseline1보다 낮은 성능**
   - Macro F1: 24.36% (Baseline1 43.28% 대비 -18.92%p)
   - **해석**: KoBERT 임베딩이 TF-IDF보다 소규모 데이터셋에서 덜 효과적
   - Accuracy는 유사한 수준 (95.00% vs 96.33%)

2. **재현성 문제 해결**
   - ✅ Baseline2 저장/로드 문제 해결 완료
   - 모델 평가 정상 작동 확인

### 결론
- **TF-IDF + LR이 KoBERT 임베딩 + SVM보다 우수한 성능**
- 소규모 데이터셋에서는 전통적 방법론이 더 효과적일 수 있음
- Baseline3 (KoBERT Fine-tuning) 평가 진행 중

---

## 종합 결론

### 실험 1 (섹션별 전용 모델)
- ✅ **연예 섹션**: 섹션별 전용 모델이 효과적 (Macro F1 +6.47%p)
- ❌ **정치/사회 섹션**: 전체 모델이 더 우수

### 실험 2 (SMOTE)
- ❌ **SMOTE는 소규모 데이터셋에서 비효과적**
- 다른 불균형 대응 기법 시도 필요

### 실험 3 (KoBERT 재현성)
- ✅ Baseline2 저장/로드 문제 해결
- 🔄 Baseline3 평가 진행 중

### 논문에 반영할 내용
1. 섹션별 특성에 따른 모델 전략 차별화의 필요성
2. 소규모 데이터셋에서의 불균형 대응 기법 한계
3. KoBERT 기반 모델의 성능 비교 (완료 후)

